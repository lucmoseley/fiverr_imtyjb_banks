{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc8dec7-0f72-4a89-be11-1341be6fc32e",
   "metadata": {},
   "source": [
    "# Import relevant modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0424aee4-1828-40b4-96e2-f55ccbad05a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import relevant modules\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43566e23-5667-40b3-ac1b-4fbfd14e2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modified & cleaned personal loan data into a Pandas DataFrame\n",
    "df_loan_data = pd.read_pickle('df_loan_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16b87f-5e16-44ff-ad54-d087c4ba1e3a",
   "metadata": {},
   "source": [
    "# Transform data to suit the LGBM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e349ac-8018-41b0-ac39-3ab485a1bd8e",
   "metadata": {},
   "source": [
    "LGBM models do not require scaling, even though the data is pre-scaled from the data_preparation notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0893a87f-aad7-41e6-a4a0-e18f7bdf081c",
   "metadata": {},
   "source": [
    "LGBM models do perform better with balanced classes (and this data has reasonably strong imbalance). This re-balancing will be handled within the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cff79c-987e-4bd3-83ef-deb2cc7135d6",
   "metadata": {},
   "source": [
    "# Optimize the model as constructed in LGBM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2fa1b9-fe88-41f6-a396-998de1e47e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target_variable = 'personal_loan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f88f09-6bfd-4dc7-91ba-3b023143cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress LightGBM UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50391fef-298c-497f-a5a3-86433e96d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df_loan_data.drop(columns=[target_variable])\n",
    "y = df_loan_data[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20afbf7a-7c2f-4222-bb61-cd3c1341b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e6ea4f-3212-44b4-9888-04b908a5721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.7),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 0.7),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 20),  # Adjust the range as needed\n",
    "    }\n",
    "\n",
    "    auc_scores = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_index, valid_index in skf.split(X, y):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "        # Apply SMOTE for class balancing\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Create a LightGBM Dataset\n",
    "        train_data = lgb.Dataset(X_train_resampled, label=y_train_resampled)\n",
    "        valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "\n",
    "        # Redirect output to null device to suppress all output\n",
    "        devnull = open(os.devnull, 'w')\n",
    "        stdout_backup = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "\n",
    "        # Train the model with custom early stopping and 'log_evaluation' callback\n",
    "        callbacks = [lgb.callback.log_evaluation(period=1)]\n",
    "        bst = lgb.train(params, train_data, valid_sets=[valid_data], callbacks=callbacks)\n",
    "\n",
    "        # Restore the standard output\n",
    "        sys.stdout = stdout_backup\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        auc = bst.best_score['valid_0']['auc']\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    # Calculate the mean AUC score across cross-validation folds\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    return mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f673e2b-e17d-46d5-a3ab-f6eff7b71fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-13 22:07:50,750] A new study created in memory with name: no-name-6b7eaf59-f8b8-49a2-9be0-a32c92d78825\n",
      "[I 2023-10-13 22:07:52,339] Trial 0 finished with value: 0.9491438778024144 and parameters: {'learning_rate': 0.042610869903360854, 'n_estimators': 249, 'max_depth': 4, 'subsample': 0.6433951357590532, 'feature_fraction': 0.6934786290291781, 'num_leaves': 27, 'min_child_samples': 17}. Best is trial 0 with value: 0.9491438778024144.\n",
      "[I 2023-10-13 22:07:54,540] Trial 1 finished with value: 0.9456836659275684 and parameters: {'learning_rate': 0.06927835588411228, 'n_estimators': 233, 'max_depth': 6, 'subsample': 0.6015721928232459, 'feature_fraction': 0.6622876754807476, 'num_leaves': 24, 'min_child_samples': 7}. Best is trial 0 with value: 0.9491438778024144.\n",
      "[I 2023-10-13 22:07:55,309] Trial 2 finished with value: 0.9497770386794777 and parameters: {'learning_rate': 0.08076751291440921, 'n_estimators': 184, 'max_depth': 3, 'subsample': 0.5487115584734424, 'feature_fraction': 0.6045232917031182, 'num_leaves': 21, 'min_child_samples': 10}. Best is trial 2 with value: 0.9497770386794777.\n",
      "[I 2023-10-13 22:07:58,460] Trial 3 finished with value: 0.9479046563192904 and parameters: {'learning_rate': 0.029295352161711762, 'n_estimators': 197, 'max_depth': 6, 'subsample': 0.5968811921505707, 'feature_fraction': 0.5800395376140692, 'num_leaves': 44, 'min_child_samples': 6}. Best is trial 2 with value: 0.9497770386794777.\n",
      "[I 2023-10-13 22:07:59,107] Trial 4 finished with value: 0.9505758807588076 and parameters: {'learning_rate': 0.06120862165700555, 'n_estimators': 138, 'max_depth': 3, 'subsample': 0.5861748078371984, 'feature_fraction': 0.6816730554676883, 'num_leaves': 28, 'min_child_samples': 16}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:00,093] Trial 5 finished with value: 0.9500997782705101 and parameters: {'learning_rate': 0.043319582203501704, 'n_estimators': 138, 'max_depth': 4, 'subsample': 0.5776084981292479, 'feature_fraction': 0.6064976905234157, 'num_leaves': 29, 'min_child_samples': 13}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:01,422] Trial 6 finished with value: 0.9498989898989899 and parameters: {'learning_rate': 0.060065454134732695, 'n_estimators': 291, 'max_depth': 3, 'subsample': 0.5386740480598373, 'feature_fraction': 0.5515531412806324, 'num_leaves': 33, 'min_child_samples': 7}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:03,510] Trial 7 finished with value: 0.9468255728011826 and parameters: {'learning_rate': 0.07822563335723938, 'n_estimators': 199, 'max_depth': 5, 'subsample': 0.6742871328788852, 'feature_fraction': 0.6679872422899278, 'num_leaves': 24, 'min_child_samples': 10}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:05,225] Trial 8 finished with value: 0.9472862774082286 and parameters: {'learning_rate': 0.07819749220214664, 'n_estimators': 177, 'max_depth': 5, 'subsample': 0.696665130409214, 'feature_fraction': 0.6688351603191941, 'num_leaves': 31, 'min_child_samples': 17}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:08,228] Trial 9 finished with value: 0.9446834195614684 and parameters: {'learning_rate': 0.0674639775041281, 'n_estimators': 211, 'max_depth': 6, 'subsample': 0.5996128043787471, 'feature_fraction': 0.5343422334551301, 'num_leaves': 44, 'min_child_samples': 12}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:08,848] Trial 10 finished with value: 0.9504834934712983 and parameters: {'learning_rate': 0.09165810569953653, 'n_estimators': 105, 'max_depth': 3, 'subsample': 0.5016783188998185, 'feature_fraction': 0.5066941931292989, 'num_leaves': 38, 'min_child_samples': 20}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:09,332] Trial 11 finished with value: 0.9498965262379897 and parameters: {'learning_rate': 0.09971204410212965, 'n_estimators': 100, 'max_depth': 3, 'subsample': 0.5108020526112488, 'feature_fraction': 0.5078993979580559, 'num_leaves': 38, 'min_child_samples': 20}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:10,029] Trial 12 finished with value: 0.9378387533875339 and parameters: {'learning_rate': 0.014617731698189973, 'n_estimators': 105, 'max_depth': 4, 'subsample': 0.5011135747442574, 'feature_fraction': 0.5085949765577134, 'num_leaves': 38, 'min_child_samples': 20}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:10,651] Trial 13 finished with value: 0.9497671840354768 and parameters: {'learning_rate': 0.09752900145850468, 'n_estimators': 143, 'max_depth': 3, 'subsample': 0.5381752424249858, 'feature_fraction': 0.6390047635266943, 'num_leaves': 38, 'min_child_samples': 16}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:11,531] Trial 14 finished with value: 0.9501743040157674 and parameters: {'learning_rate': 0.05026356863005417, 'n_estimators': 129, 'max_depth': 4, 'subsample': 0.5655827786102038, 'feature_fraction': 0.5753324483275123, 'num_leaves': 47, 'min_child_samples': 18}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:12,229] Trial 15 finished with value: 0.9501835427445183 and parameters: {'learning_rate': 0.08835318652800314, 'n_estimators': 160, 'max_depth': 3, 'subsample': 0.5114323720724993, 'feature_fraction': 0.6245435389858405, 'num_leaves': 35, 'min_child_samples': 15}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:12,761] Trial 16 finished with value: 0.9497585612219759 and parameters: {'learning_rate': 0.06050705544768532, 'n_estimators': 119, 'max_depth': 3, 'subsample': 0.6271569804268708, 'feature_fraction': 0.5423150499284629, 'num_leaves': 41, 'min_child_samples': 19}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:14,270] Trial 17 finished with value: 0.9458770633160878 and parameters: {'learning_rate': 0.08961299620469272, 'n_estimators': 155, 'max_depth': 5, 'subsample': 0.5276274824388336, 'feature_fraction': 0.6992353626617893, 'num_leaves': 50, 'min_child_samples': 14}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:15,277] Trial 18 finished with value: 0.9500708302537572 and parameters: {'learning_rate': 0.06791194238321123, 'n_estimators': 118, 'max_depth': 4, 'subsample': 0.5478583200851843, 'feature_fraction': 0.5745716364680418, 'num_leaves': 29, 'min_child_samples': 18}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:15,993] Trial 19 finished with value: 0.9504656319290465 and parameters: {'learning_rate': 0.05324680979847088, 'n_estimators': 164, 'max_depth': 3, 'subsample': 0.5191447639139319, 'feature_fraction': 0.6328512869986399, 'num_leaves': 34, 'min_child_samples': 15}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:17,911] Trial 20 finished with value: 0.9454434589800442 and parameters: {'learning_rate': 0.08996172300321947, 'n_estimators': 298, 'max_depth': 4, 'subsample': 0.5622773909185176, 'feature_fraction': 0.5236426299785668, 'num_leaves': 20, 'min_child_samples': 11}. Best is trial 4 with value: 0.9505758807588076.\n",
      "[I 2023-10-13 22:08:18,664] Trial 21 finished with value: 0.9508093126385809 and parameters: {'learning_rate': 0.052799389124828684, 'n_estimators': 167, 'max_depth': 3, 'subsample': 0.5212991305984513, 'feature_fraction': 0.6356906023167532, 'num_leaves': 34, 'min_child_samples': 15}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:19,284] Trial 22 finished with value: 0.9503116531165311 and parameters: {'learning_rate': 0.07179301390902813, 'n_estimators': 143, 'max_depth': 3, 'subsample': 0.5045134626352344, 'feature_fraction': 0.5017960437681176, 'num_leaves': 32, 'min_child_samples': 16}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:19,825] Trial 23 finished with value: 0.9506270017245628 and parameters: {'learning_rate': 0.05867948100514442, 'n_estimators': 116, 'max_depth': 3, 'subsample': 0.5237436207191851, 'feature_fraction': 0.6491293244773427, 'num_leaves': 37, 'min_child_samples': 14}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:20,590] Trial 24 finished with value: 0.9506393200295641 and parameters: {'learning_rate': 0.05867575158599199, 'n_estimators': 179, 'max_depth': 3, 'subsample': 0.5271405466492338, 'feature_fraction': 0.650273189193572, 'num_leaves': 29, 'min_child_samples': 13}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:21,732] Trial 25 finished with value: 0.94990022172949 and parameters: {'learning_rate': 0.05076338315539233, 'n_estimators': 178, 'max_depth': 4, 'subsample': 0.532448221852138, 'feature_fraction': 0.6482525975363947, 'num_leaves': 41, 'min_child_samples': 13}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:22,697] Trial 26 finished with value: 0.9502746982015274 and parameters: {'learning_rate': 0.056771892370349464, 'n_estimators': 211, 'max_depth': 3, 'subsample': 0.5192300988376032, 'feature_fraction': 0.6221934650902824, 'num_leaves': 36, 'min_child_samples': 14}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:24,193] Trial 27 finished with value: 0.9488001970928801 and parameters: {'learning_rate': 0.044621321083673414, 'n_estimators': 238, 'max_depth': 4, 'subsample': 0.5239425429369897, 'feature_fraction': 0.6480121489109423, 'num_leaves': 31, 'min_child_samples': 9}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:25,239] Trial 28 finished with value: 0.9499057649667405 and parameters: {'learning_rate': 0.0347326729754765, 'n_estimators': 169, 'max_depth': 3, 'subsample': 0.552501017270832, 'feature_fraction': 0.6556186312708888, 'num_leaves': 26, 'min_child_samples': 12}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:26,929] Trial 29 finished with value: 0.9489085981768909 and parameters: {'learning_rate': 0.04906012122536338, 'n_estimators': 261, 'max_depth': 4, 'subsample': 0.5319808469880832, 'feature_fraction': 0.6775402360528594, 'num_leaves': 41, 'min_child_samples': 14}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:28,644] Trial 30 finished with value: 0.9481805863513181 and parameters: {'learning_rate': 0.05654344747838763, 'n_estimators': 153, 'max_depth': 5, 'subsample': 0.5225064410968471, 'feature_fraction': 0.6908602970112823, 'num_leaves': 36, 'min_child_samples': 11}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:29,386] Trial 31 finished with value: 0.9505974377925599 and parameters: {'learning_rate': 0.062219639564148665, 'n_estimators': 125, 'max_depth': 3, 'subsample': 0.5770703707434213, 'feature_fraction': 0.6801624880256522, 'num_leaves': 28, 'min_child_samples': 16}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:29,952] Trial 32 finished with value: 0.9507058388765705 and parameters: {'learning_rate': 0.06589097909538559, 'n_estimators': 117, 'max_depth': 3, 'subsample': 0.5637514418032075, 'feature_fraction': 0.6554576317625863, 'num_leaves': 26, 'min_child_samples': 15}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:30,814] Trial 33 finished with value: 0.9504847253017985 and parameters: {'learning_rate': 0.06351049189683981, 'n_estimators': 189, 'max_depth': 3, 'subsample': 0.5471362304826503, 'feature_fraction': 0.658318373981047, 'num_leaves': 24, 'min_child_samples': 15}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:31,394] Trial 34 finished with value: 0.9506085242670608 and parameters: {'learning_rate': 0.055884785502166606, 'n_estimators': 126, 'max_depth': 3, 'subsample': 0.5575128709926739, 'feature_fraction': 0.6414715365561459, 'num_leaves': 22, 'min_child_samples': 13}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:31,909] Trial 35 finished with value: 0.9505826558265582 and parameters: {'learning_rate': 0.07499101509570245, 'n_estimators': 113, 'max_depth': 3, 'subsample': 0.5398513231712886, 'feature_fraction': 0.6593184858093208, 'num_leaves': 25, 'min_child_samples': 17}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:32,809] Trial 36 finished with value: 0.9502463661000247 and parameters: {'learning_rate': 0.06554030249073782, 'n_estimators': 217, 'max_depth': 3, 'subsample': 0.513499790732745, 'feature_fraction': 0.6202469041569252, 'num_leaves': 31, 'min_child_samples': 14}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:34,019] Trial 37 finished with value: 0.9485636856368563 and parameters: {'learning_rate': 0.07008050978087932, 'n_estimators': 187, 'max_depth': 4, 'subsample': 0.5426564246482694, 'feature_fraction': 0.6326986509964769, 'num_leaves': 27, 'min_child_samples': 11}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:34,677] Trial 38 finished with value: 0.9503658536585367 and parameters: {'learning_rate': 0.07233187821282455, 'n_estimators': 150, 'max_depth': 3, 'subsample': 0.5331812693378151, 'feature_fraction': 0.6121878327879485, 'num_leaves': 30, 'min_child_samples': 8}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:36,089] Trial 39 finished with value: 0.9486178861788618 and parameters: {'learning_rate': 0.05881969353341588, 'n_estimators': 132, 'max_depth': 6, 'subsample': 0.5563966119824282, 'feature_fraction': 0.6504000785439052, 'num_leaves': 22, 'min_child_samples': 15}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:36,837] Trial 40 finished with value: 0.9501755358462676 and parameters: {'learning_rate': 0.06404330217665363, 'n_estimators': 176, 'max_depth': 3, 'subsample': 0.5678858441203002, 'feature_fraction': 0.6612756458236907, 'num_leaves': 33, 'min_child_samples': 12}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:37,355] Trial 41 finished with value: 0.9501835427445184 and parameters: {'learning_rate': 0.05449728443136857, 'n_estimators': 111, 'max_depth': 3, 'subsample': 0.554798944898256, 'feature_fraction': 0.6412828508081421, 'num_leaves': 22, 'min_child_samples': 13}. Best is trial 21 with value: 0.9508093126385809.\n",
      "[I 2023-10-13 22:08:37,955] Trial 42 finished with value: 0.9508838383838384 and parameters: {'learning_rate': 0.05866434270613241, 'n_estimators': 134, 'max_depth': 3, 'subsample': 0.5280281932069381, 'feature_fraction': 0.6409230993459508, 'num_leaves': 23, 'min_child_samples': 13}. Best is trial 42 with value: 0.9508838383838384.\n",
      "[I 2023-10-13 22:08:38,587] Trial 43 finished with value: 0.9506423996058142 and parameters: {'learning_rate': 0.04624313098862754, 'n_estimators': 141, 'max_depth': 3, 'subsample': 0.5274439609034719, 'feature_fraction': 0.6687157305252343, 'num_leaves': 26, 'min_child_samples': 5}. Best is trial 42 with value: 0.9508838383838384.\n",
      "[I 2023-10-13 22:08:39,211] Trial 44 finished with value: 0.9505438531658044 and parameters: {'learning_rate': 0.048047351421093835, 'n_estimators': 137, 'max_depth': 3, 'subsample': 0.5430968171259964, 'feature_fraction': 0.6664001369721164, 'num_leaves': 26, 'min_child_samples': 5}. Best is trial 42 with value: 0.9508838383838384.\n",
      "[I 2023-10-13 22:08:39,971] Trial 45 finished with value: 0.9504834934712983 and parameters: {'learning_rate': 0.039708657840691344, 'n_estimators': 169, 'max_depth': 3, 'subsample': 0.5128188344993255, 'feature_fraction': 0.6690633767647799, 'num_leaves': 23, 'min_child_samples': 7}. Best is trial 42 with value: 0.9508838383838384.\n",
      "[I 2023-10-13 22:08:40,973] Trial 46 finished with value: 0.9503399852180341 and parameters: {'learning_rate': 0.04649955701731998, 'n_estimators': 147, 'max_depth': 4, 'subsample': 0.5310865338139301, 'feature_fraction': 0.6743497446008597, 'num_leaves': 27, 'min_child_samples': 10}. Best is trial 42 with value: 0.9508838383838384.\n",
      "[I 2023-10-13 22:08:41,834] Trial 47 finished with value: 0.9500862281350086 and parameters: {'learning_rate': 0.05236429672145338, 'n_estimators': 196, 'max_depth': 3, 'subsample': 0.5374641212988333, 'feature_fraction': 0.6865983195878531, 'num_leaves': 29, 'min_child_samples': 6}. Best is trial 42 with value: 0.9508838383838384.\n",
      "[I 2023-10-13 22:08:42,522] Trial 48 finished with value: 0.9509090909090909 and parameters: {'learning_rate': 0.06481378474357612, 'n_estimators': 135, 'max_depth': 3, 'subsample': 0.5005138022002019, 'feature_fraction': 0.6731566197862116, 'num_leaves': 20, 'min_child_samples': 9}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:43,476] Trial 49 finished with value: 0.9499926090169992 and parameters: {'learning_rate': 0.04264215280375869, 'n_estimators': 136, 'max_depth': 4, 'subsample': 0.5100100101832634, 'feature_fraction': 0.6752712656542111, 'num_leaves': 20, 'min_child_samples': 5}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:44,177] Trial 50 finished with value: 0.9504255974377926 and parameters: {'learning_rate': 0.06521811092092207, 'n_estimators': 159, 'max_depth': 3, 'subsample': 0.5014499281419579, 'feature_fraction': 0.6834621934301718, 'num_leaves': 24, 'min_child_samples': 8}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:44,814] Trial 51 finished with value: 0.9506621088938163 and parameters: {'learning_rate': 0.06057134356433085, 'n_estimators': 144, 'max_depth': 3, 'subsample': 0.5179975953416261, 'feature_fraction': 0.6643691528832191, 'num_leaves': 24, 'min_child_samples': 9}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:45,379] Trial 52 finished with value: 0.9505210643015521 and parameters: {'learning_rate': 0.06845333505062166, 'n_estimators': 124, 'max_depth': 3, 'subsample': 0.5139957877511653, 'feature_fraction': 0.6663832861781133, 'num_leaves': 21, 'min_child_samples': 9}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:46,010] Trial 53 finished with value: 0.950259300320276 and parameters: {'learning_rate': 0.06208349656183519, 'n_estimators': 142, 'max_depth': 3, 'subsample': 0.5017789811509084, 'feature_fraction': 0.6910040748615721, 'num_leaves': 25, 'min_child_samples': 10}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:46,489] Trial 54 finished with value: 0.9496249076127125 and parameters: {'learning_rate': 0.05395230555661962, 'n_estimators': 101, 'max_depth': 3, 'subsample': 0.5215498665585043, 'feature_fraction': 0.6993926761935325, 'num_leaves': 23, 'min_child_samples': 6}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:47,088] Trial 55 finished with value: 0.9505980537078098 and parameters: {'learning_rate': 0.0669567048971339, 'n_estimators': 132, 'max_depth': 3, 'subsample': 0.5080044585842272, 'feature_fraction': 0.6699751788088486, 'num_leaves': 20, 'min_child_samples': 8}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:47,604] Trial 56 finished with value: 0.9499396403054939 and parameters: {'learning_rate': 0.05132834072883094, 'n_estimators': 110, 'max_depth': 3, 'subsample': 0.5174477067848565, 'feature_fraction': 0.6609285202549494, 'num_leaves': 25, 'min_child_samples': 17}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:49,021] Trial 57 finished with value: 0.9480130574033014 and parameters: {'learning_rate': 0.06120246050093519, 'n_estimators': 152, 'max_depth': 6, 'subsample': 0.5075530147212076, 'feature_fraction': 0.6552841697070005, 'num_leaves': 21, 'min_child_samples': 7}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:49,666] Trial 58 finished with value: 0.9501638334565163 and parameters: {'learning_rate': 0.08118630603101022, 'n_estimators': 144, 'max_depth': 3, 'subsample': 0.5463819172612914, 'feature_fraction': 0.6813938454338729, 'num_leaves': 23, 'min_child_samples': 9}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:50,403] Trial 59 finished with value: 0.9506054446908105 and parameters: {'learning_rate': 0.0467741947010569, 'n_estimators': 166, 'max_depth': 3, 'subsample': 0.5273171933701024, 'feature_fraction': 0.633328919466412, 'num_leaves': 28, 'min_child_samples': 11}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:51,573] Trial 60 finished with value: 0.9488186745503819 and parameters: {'learning_rate': 0.056094551937415194, 'n_estimators': 119, 'max_depth': 5, 'subsample': 0.5173420429911222, 'feature_fraction': 0.6733764802019204, 'num_leaves': 26, 'min_child_samples': 12}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:52,258] Trial 61 finished with value: 0.9506571815718157 and parameters: {'learning_rate': 0.05869235098184635, 'n_estimators': 158, 'max_depth': 3, 'subsample': 0.5257586714820068, 'feature_fraction': 0.6528445658715926, 'num_leaves': 27, 'min_child_samples': 13}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:52,937] Trial 62 finished with value: 0.9505457009115545 and parameters: {'learning_rate': 0.06067628747672774, 'n_estimators': 158, 'max_depth': 3, 'subsample': 0.5349945809923988, 'feature_fraction': 0.663498743965123, 'num_leaves': 24, 'min_child_samples': 15}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:53,558] Trial 63 finished with value: 0.9505561714708056 and parameters: {'learning_rate': 0.05257129103332411, 'n_estimators': 138, 'max_depth': 3, 'subsample': 0.5238671015478618, 'feature_fraction': 0.6439315045518974, 'num_leaves': 21, 'min_child_samples': 13}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:54,127] Trial 64 finished with value: 0.9506559497413155 and parameters: {'learning_rate': 0.0573938142937025, 'n_estimators': 128, 'max_depth': 3, 'subsample': 0.5000517486869094, 'feature_fraction': 0.654385549999407, 'num_leaves': 28, 'min_child_samples': 16}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:54,676] Trial 65 finished with value: 0.9506393200295639 and parameters: {'learning_rate': 0.058239716448925186, 'n_estimators': 123, 'max_depth': 3, 'subsample': 0.5065753734683307, 'feature_fraction': 0.6559420950491393, 'num_leaves': 27, 'min_child_samples': 18}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:55,554] Trial 66 finished with value: 0.9499347129834934 and parameters: {'learning_rate': 0.06510071778157715, 'n_estimators': 130, 'max_depth': 4, 'subsample': 0.5003315750129342, 'feature_fraction': 0.6350280166724152, 'num_leaves': 33, 'min_child_samples': 16}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:56,117] Trial 67 finished with value: 0.9501909337275191 and parameters: {'learning_rate': 0.06034928865133578, 'n_estimators': 105, 'max_depth': 3, 'subsample': 0.5168977837003423, 'feature_fraction': 0.6522953872663544, 'num_leaves': 30, 'min_child_samples': 15}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:56,776] Trial 68 finished with value: 0.9502900960827789 and parameters: {'learning_rate': 0.05691473721479018, 'n_estimators': 148, 'max_depth': 3, 'subsample': 0.507331144128281, 'feature_fraction': 0.6452300857279107, 'num_leaves': 44, 'min_child_samples': 14}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:57,531] Trial 69 finished with value: 0.9502432865237743 and parameters: {'learning_rate': 0.06355219447321947, 'n_estimators': 173, 'max_depth': 3, 'subsample': 0.5147244831191345, 'feature_fraction': 0.6368085431809225, 'num_leaves': 23, 'min_child_samples': 16}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:58,683] Trial 70 finished with value: 0.9498460211874846 and parameters: {'learning_rate': 0.04993902696738237, 'n_estimators': 275, 'max_depth': 3, 'subsample': 0.5389704357480044, 'feature_fraction': 0.6529639064435514, 'num_leaves': 28, 'min_child_samples': 17}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:08:59,400] Trial 71 finished with value: 0.9507329391475734 and parameters: {'learning_rate': 0.05436770886080275, 'n_estimators': 162, 'max_depth': 3, 'subsample': 0.5289601176040927, 'feature_fraction': 0.6644250877841085, 'num_leaves': 25, 'min_child_samples': 12}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:00,073] Trial 72 finished with value: 0.950610987928061 and parameters: {'learning_rate': 0.05322789989518967, 'n_estimators': 134, 'max_depth': 3, 'subsample': 0.5214914576849781, 'feature_fraction': 0.6612234903591953, 'num_leaves': 25, 'min_child_samples': 10}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:00,760] Trial 73 finished with value: 0.950731091401823 and parameters: {'learning_rate': 0.05967858457559197, 'n_estimators': 160, 'max_depth': 3, 'subsample': 0.5308093176298235, 'feature_fraction': 0.645046476313643, 'num_leaves': 22, 'min_child_samples': 14}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:01,463] Trial 74 finished with value: 0.9507625030795763 and parameters: {'learning_rate': 0.06165802885844012, 'n_estimators': 163, 'max_depth': 3, 'subsample': 0.5305140654319437, 'feature_fraction': 0.6409533366535812, 'num_leaves': 22, 'min_child_samples': 14}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:02,172] Trial 75 finished with value: 0.9504206701157921 and parameters: {'learning_rate': 0.0701552821215904, 'n_estimators': 166, 'max_depth': 3, 'subsample': 0.5309722837483644, 'feature_fraction': 0.6283479191174682, 'num_leaves': 22, 'min_child_samples': 14}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:02,945] Trial 76 finished with value: 0.9499328652377432 and parameters: {'learning_rate': 0.06802155322736358, 'n_estimators': 183, 'max_depth': 3, 'subsample': 0.5477303131465758, 'feature_fraction': 0.6420009727596456, 'num_leaves': 21, 'min_child_samples': 14}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:03,866] Trial 77 finished with value: 0.9503165804385316 and parameters: {'learning_rate': 0.06234573321077774, 'n_estimators': 194, 'max_depth': 3, 'subsample': 0.5354143614779833, 'feature_fraction': 0.6281101902641116, 'num_leaves': 20, 'min_child_samples': 12}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:04,848] Trial 78 finished with value: 0.9494025622074403 and parameters: {'learning_rate': 0.06606641922482816, 'n_estimators': 154, 'max_depth': 4, 'subsample': 0.5421460800402352, 'feature_fraction': 0.6456847905990322, 'num_leaves': 24, 'min_child_samples': 15}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:05,584] Trial 79 finished with value: 0.9507834441980784 and parameters: {'learning_rate': 0.055293062456658174, 'n_estimators': 163, 'max_depth': 3, 'subsample': 0.5304658444509693, 'feature_fraction': 0.6394887595738369, 'num_leaves': 22, 'min_child_samples': 14}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:06,439] Trial 80 finished with value: 0.9503319783197831 and parameters: {'learning_rate': 0.05464456619572859, 'n_estimators': 202, 'max_depth': 3, 'subsample': 0.5498851056450809, 'feature_fraction': 0.6382014556021961, 'num_leaves': 22, 'min_child_samples': 14}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:07,150] Trial 81 finished with value: 0.9505635624538064 and parameters: {'learning_rate': 0.06032140607640249, 'n_estimators': 163, 'max_depth': 3, 'subsample': 0.5273743214251287, 'feature_fraction': 0.6388946489301074, 'num_leaves': 23, 'min_child_samples': 15}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:07,913] Trial 82 finished with value: 0.9505493964030549 and parameters: {'learning_rate': 0.06362896082928063, 'n_estimators': 173, 'max_depth': 3, 'subsample': 0.51888156301686, 'feature_fraction': 0.6497464483268293, 'num_leaves': 20, 'min_child_samples': 13}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:08,578] Trial 83 finished with value: 0.9503479921162847 and parameters: {'learning_rate': 0.0546748646040301, 'n_estimators': 147, 'max_depth': 3, 'subsample': 0.533639958906581, 'feature_fraction': 0.6471416848509631, 'num_leaves': 22, 'min_child_samples': 12}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:09,355] Trial 84 finished with value: 0.9506577974870657 and parameters: {'learning_rate': 0.05044860939827603, 'n_estimators': 180, 'max_depth': 3, 'subsample': 0.512953761858391, 'feature_fraction': 0.6179308021498532, 'num_leaves': 40, 'min_child_samples': 14}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:10,143] Trial 85 finished with value: 0.9504896526237989 and parameters: {'learning_rate': 0.05882581298522405, 'n_estimators': 161, 'max_depth': 3, 'subsample': 0.539661351312546, 'feature_fraction': 0.6627052612704672, 'num_leaves': 24, 'min_child_samples': 14}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:10,826] Trial 86 finished with value: 0.950519216555802 and parameters: {'learning_rate': 0.06285683959834112, 'n_estimators': 153, 'max_depth': 3, 'subsample': 0.5306593837605229, 'feature_fraction': 0.6296153482946215, 'num_leaves': 50, 'min_child_samples': 9}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:11,573] Trial 87 finished with value: 0.9506824340970683 and parameters: {'learning_rate': 0.05548154130138149, 'n_estimators': 172, 'max_depth': 3, 'subsample': 0.5226000935816375, 'feature_fraction': 0.6236185299988911, 'num_leaves': 21, 'min_child_samples': 15}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:12,306] Trial 88 finished with value: 0.9508259423503326 and parameters: {'learning_rate': 0.05593183518149191, 'n_estimators': 170, 'max_depth': 3, 'subsample': 0.5439402455092588, 'feature_fraction': 0.6162213076724413, 'num_leaves': 21, 'min_child_samples': 15}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:13,141] Trial 89 finished with value: 0.950890613451589 and parameters: {'learning_rate': 0.0483713186040608, 'n_estimators': 190, 'max_depth': 3, 'subsample': 0.5525294725336425, 'feature_fraction': 0.6178082887319368, 'num_leaves': 22, 'min_child_samples': 13}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:14,012] Trial 90 finished with value: 0.9507187730968217 and parameters: {'learning_rate': 0.048613045813740784, 'n_estimators': 203, 'max_depth': 3, 'subsample': 0.542296228809894, 'feature_fraction': 0.6136338049645229, 'num_leaves': 20, 'min_child_samples': 13}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:14,828] Trial 91 finished with value: 0.950890613451589 and parameters: {'learning_rate': 0.04762724198888485, 'n_estimators': 189, 'max_depth': 3, 'subsample': 0.5435038638830737, 'feature_fraction': 0.6083497424983241, 'num_leaves': 22, 'min_child_samples': 13}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:15,633] Trial 92 finished with value: 0.9508789110618379 and parameters: {'learning_rate': 0.05213989093732993, 'n_estimators': 188, 'max_depth': 3, 'subsample': 0.5507077710530351, 'feature_fraction': 0.603769923953091, 'num_leaves': 21, 'min_child_samples': 12}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:16,654] Trial 93 finished with value: 0.950280857354028 and parameters: {'learning_rate': 0.05185833198281392, 'n_estimators': 223, 'max_depth': 3, 'subsample': 0.5544073963721535, 'feature_fraction': 0.5997077993137163, 'num_leaves': 21, 'min_child_samples': 12}. Best is trial 48 with value: 0.9509090909090909.\n",
      "[I 2023-10-13 22:09:17,485] Trial 94 finished with value: 0.9509392707563439 and parameters: {'learning_rate': 0.04386668304533329, 'n_estimators': 187, 'max_depth': 3, 'subsample': 0.558386012743904, 'feature_fraction': 0.6054855311843562, 'num_leaves': 23, 'min_child_samples': 11}. Best is trial 94 with value: 0.9509392707563439.\n",
      "[I 2023-10-13 22:09:18,315] Trial 95 finished with value: 0.9508259423503327 and parameters: {'learning_rate': 0.04410217792390758, 'n_estimators': 193, 'max_depth': 3, 'subsample': 0.5507761842035654, 'feature_fraction': 0.6039663738656385, 'num_leaves': 23, 'min_child_samples': 11}. Best is trial 94 with value: 0.9509392707563439.\n",
      "[I 2023-10-13 22:09:19,152] Trial 96 finished with value: 0.9506356245380637 and parameters: {'learning_rate': 0.0445449979096989, 'n_estimators': 190, 'max_depth': 3, 'subsample': 0.5585057013069729, 'feature_fraction': 0.6032003126272286, 'num_leaves': 23, 'min_child_samples': 11}. Best is trial 94 with value: 0.9509392707563439.\n",
      "[I 2023-10-13 22:09:20,039] Trial 97 finished with value: 0.9505968218773097 and parameters: {'learning_rate': 0.04813535101243395, 'n_estimators': 205, 'max_depth': 3, 'subsample': 0.5531570004237611, 'feature_fraction': 0.6075260637373974, 'num_leaves': 21, 'min_child_samples': 11}. Best is trial 94 with value: 0.9509392707563439.\n",
      "[I 2023-10-13 22:09:21,605] Trial 98 finished with value: 0.949331116038433 and parameters: {'learning_rate': 0.041262435749723055, 'n_estimators': 192, 'max_depth': 5, 'subsample': 0.5611594759200134, 'feature_fraction': 0.5941190667888336, 'num_leaves': 20, 'min_child_samples': 10}. Best is trial 94 with value: 0.9509392707563439.\n",
      "[I 2023-10-13 22:09:22,785] Trial 99 finished with value: 0.949979058881498 and parameters: {'learning_rate': 0.0454050428473034, 'n_estimators': 183, 'max_depth': 4, 'subsample': 0.5678758003532759, 'feature_fraction': 0.6183147557805364, 'num_leaves': 23, 'min_child_samples': 13}. Best is trial 94 with value: 0.9509392707563439.\n"
     ]
    }
   ],
   "source": [
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ede571c9-41b8-4628-b756-fde8fc208539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.04386668304533329, 'n_estimators': 187, 'max_depth': 3, 'subsample': 0.558386012743904, 'feature_fraction': 0.6054855311843562, 'num_leaves': 23, 'min_child_samples': 11}\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print('Best Hyperparameters: {}'.format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96a468a-cc6b-4ab5-a359-6dfba0421cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best params\n",
    "with open('LGBM_best_params.pkl', 'wb') as file:\n",
    "    pickle.dump(best_params, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20a47a-6db6-47b9-92d1-804fab380cae",
   "metadata": {},
   "source": [
    "# Train and evaluate a model using the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c1e44b-779b-4345-b1cb-a25f25353b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results from best model\n",
    "auc_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c4d02bc-a5c5-4c78-a116-db72af46bffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1289\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1293\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1294\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1291\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1290\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Apply SMOTE to oversample the minority class\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Create a LightGBM Dataset\n",
    "    train_data = lgb.Dataset(X_train_resampled, label=y_train_resampled)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    num_round = 100\n",
    "    bst = lgb.train(best_params, train_data, num_round, valid_sets=[test_data], early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    auc_scores.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3efc7a6-4f6b-4922-98a3-df615197082a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.9466605075141661\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean AUC score across cross-validation folds\n",
    "mean_auc = np.mean(auc_scores)\n",
    "print('Mean AUC: {}'.format(mean_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0dfcb-54af-4a40-b702-a71596f9c75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb338122-0ca5-4174-aa1a-edfd69457c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7dcbd-023a-472f-b694-511194445daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df58f3-229a-4e24-9419-39d8a59ea632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
