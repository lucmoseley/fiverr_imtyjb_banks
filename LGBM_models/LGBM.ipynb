{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc8dec7-0f72-4a89-be11-1341be6fc32e",
   "metadata": {},
   "source": [
    "# Import relevant modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0424aee4-1828-40b4-96e2-f55ccbad05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43566e23-5667-40b3-ac1b-4fbfd14e2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modified & cleaned personal loan data into a Pandas DataFrame\n",
    "df_loan_data = pd.read_pickle('df_loan_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16b87f-5e16-44ff-ad54-d087c4ba1e3a",
   "metadata": {},
   "source": [
    "# Transform data to suit the LGBM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e349ac-8018-41b0-ac39-3ab485a1bd8e",
   "metadata": {},
   "source": [
    "LGBM models do not require scaling, even though the data is pre-scaled from the data_preparation notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0893a87f-aad7-41e6-a4a0-e18f7bdf081c",
   "metadata": {},
   "source": [
    "LGBM models do perform better with balanced classes (and this data has reasonably strong imbalance). This re-balancing will be handled via SMOTE techniques within model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cff79c-987e-4bd3-83ef-deb2cc7135d6",
   "metadata": {},
   "source": [
    "# Train a model on all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2fa1b9-fe88-41f6-a396-998de1e47e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target_variable = 'personal_loan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e46d54d1-0f06-4afc-b2c9-a2cbf7ae9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df_loan_data.drop(columns=[target_variable])\n",
    "y = df_loan_data[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac98884-e3db-4dc8-826e-a56df3a58fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate' : 0.1,\n",
    "    'n_estimators' : 500,\n",
    "    'max_depth' : 3,\n",
    "    'subsample' : 0.5,\n",
    "    'feature_fraction' : 0.7,\n",
    "    'num_leaves' : 30,\n",
    "    'min_child_samples' : 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a96a1d08-d1bb-40af-a47e-3e56049e8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cross-validation\n",
    "n_splits = 5  # You can adjust the number of folds\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc1dbef-acf5-4400-9265-67a6cfd57515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store results\n",
    "auc_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0cbbb92-447d-4737-8e26-69191725b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3608, number of negative: 3608\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1289\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3608, number of negative: 3608\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1293\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3608, number of negative: 3608\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1294\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3608, number of negative: 3608\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1291\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 3608, number of negative: 3608\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1290\n",
      "[LightGBM] [Info] Number of data points in the train set: 7216, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/clarerigby/anaconda3/envs/fiverr_imtyjb_banks/lib/python3.11/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Apply SMOTE to oversample the minority class\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Create a LightGBM Dataset\n",
    "    train_data = lgb.Dataset(X_train_resampled, label=y_train_resampled)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    num_round = 100\n",
    "    bst = lgb.train(params, train_data, num_round, valid_sets=[test_data], early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    auc_scores.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5366de8-1b9a-43ee-b201-45b099fceb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.9506602611480659\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean AUC score across cross-validation folds\n",
    "mean_auc = np.mean(auc_scores)\n",
    "print('Mean AUC: {}'.format(mean_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cfb74-8219-4a97-86b6-27f3b0ad9e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
